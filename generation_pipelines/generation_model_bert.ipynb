{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"generation_model_bert.ipynb","provenance":[{"file_id":"1aiDddSZvIZsM1w1Pd6t4mxtThfuFBUIX","timestamp":1617733242058}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"28a674e210df4e2fb759dcd282458290":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8a371a3be7bc41aab7b2855eafdb6125","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e120e8b1459d4152b4a9a6e77bbc9b26","IPY_MODEL_8ff48795ef8343d98da8c65e4d5df0e7","IPY_MODEL_7f179d157d5144468e115b2ce995cea6"]}},"8a371a3be7bc41aab7b2855eafdb6125":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e120e8b1459d4152b4a9a6e77bbc9b26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_736effb3fd8943e0823eedac3be77ba0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2a43df6a77ba40878c23cd35fdee4f5f"}},"8ff48795ef8343d98da8c65e4d5df0e7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_dcdea7fa0166432484a31580b8e79bc1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":20,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":20,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a0eb35fcc6b04807a5dfcb45cb0a1483"}},"7f179d157d5144468e115b2ce995cea6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7e07e672d47d40d6a5fb43ed6bd02887","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 20/20 [10:15&lt;00:00, 30.76s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8b4191948b584b588f20f374691e0e1e"}},"736effb3fd8943e0823eedac3be77ba0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2a43df6a77ba40878c23cd35fdee4f5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dcdea7fa0166432484a31580b8e79bc1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a0eb35fcc6b04807a5dfcb45cb0a1483":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7e07e672d47d40d6a5fb43ed6bd02887":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8b4191948b584b588f20f374691e0e1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fc3021ecf93f433d8b3ef7aa2c0c161a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c199c2933b284e6aa4cb98e0f56d52c1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d24d1a4d33fe455e979377ff7732ccb9","IPY_MODEL_d20629a3ae2c436eae99c2ccd97e89d8","IPY_MODEL_8a05072c5a6746d5bd88dd010f3a53c7"]}},"c199c2933b284e6aa4cb98e0f56d52c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d24d1a4d33fe455e979377ff7732ccb9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_50b645bd88d54f0e88aed1cf2d845d8b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_766564d2582145359d0d9875e46c119c"}},"d20629a3ae2c436eae99c2ccd97e89d8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_158b80c54af8464fbaebf07af0a4d0ce","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":40,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":40,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3cd2e3adc5a448ffbacf87c82497df1d"}},"8a05072c5a6746d5bd88dd010f3a53c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8d2ef5761efc4c12b6d940c26af7296a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 40/40 [00:00&lt;00:00, 1063.38it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_17b8e81a338a485487e0ecf80f2e86bf"}},"50b645bd88d54f0e88aed1cf2d845d8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"766564d2582145359d0d9875e46c119c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"158b80c54af8464fbaebf07af0a4d0ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3cd2e3adc5a448ffbacf87c82497df1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8d2ef5761efc4c12b6d940c26af7296a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"17b8e81a338a485487e0ecf80f2e86bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c2a6534214664e43b9020fb99d918fcc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cf1b340bec934f3497edff52909f1192","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_70f71f39a8d44a7189560de131994dfe","IPY_MODEL_42e29973b0f548a5b1dbea8cc56705bc","IPY_MODEL_6872508b3fe14e82aa89defc2cc8c27a"]}},"cf1b340bec934f3497edff52909f1192":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"70f71f39a8d44a7189560de131994dfe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dfd1241c3c4942cd9f52f0243a070090","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_27d3e5c63dff435aad75f85d957487cf"}},"42e29973b0f548a5b1dbea8cc56705bc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e673a3c245d04a729ba4ef7538224dbb","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_788d6dd63eb24f41afaedfe7e3559946"}},"6872508b3fe14e82aa89defc2cc8c27a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_edae84f822aa4fc6a7589875f81895f2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:01&lt;00:00,  1.60s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e6867fd02a44438bbf64e290811ab76d"}},"dfd1241c3c4942cd9f52f0243a070090":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"27d3e5c63dff435aad75f85d957487cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e673a3c245d04a729ba4ef7538224dbb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"788d6dd63eb24f41afaedfe7e3559946":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"edae84f822aa4fc6a7589875f81895f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e6867fd02a44438bbf64e290811ab76d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"483b52f5c60742ae99bd327272a73678":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0731336725ce4695a1a59580fa46f291","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e06c0afe8534487c9c5d6dc445320cc6","IPY_MODEL_154ae5f748f349f88e4beeae2c3e57fc","IPY_MODEL_a8cf05838eed45f89dac6221936688c3"]}},"0731336725ce4695a1a59580fa46f291":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e06c0afe8534487c9c5d6dc445320cc6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d7ca8b4c0a5242599837e251d9b32307","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_117c945d401e4e4ca221970caf46f75c"}},"154ae5f748f349f88e4beeae2c3e57fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0908ee1b10994d28a763026034198c61","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f2e7338ead9a4dedae516f0803c02aaa"}},"a8cf05838eed45f89dac6221936688c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_40ea2470257140d99e0fd8f9b657c588","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:00&lt;00:00, 13.95it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e2809e3824d941e4ae3f05efaece9294"}},"d7ca8b4c0a5242599837e251d9b32307":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"117c945d401e4e4ca221970caf46f75c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0908ee1b10994d28a763026034198c61":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f2e7338ead9a4dedae516f0803c02aaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"40ea2470257140d99e0fd8f9b657c588":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e2809e3824d941e4ae3f05efaece9294":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"26ac92ef5e85432587c9b565ed8710b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6333f574423846f2a4d12f9e5b63c999","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_96ff87e1a1164975b3042e1bf9f2d348","IPY_MODEL_80c5541bc989413486a05a63dbefc877"]}},"6333f574423846f2a4d12f9e5b63c999":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"96ff87e1a1164975b3042e1bf9f2d348":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e3f8726cab8347438ffb1dc97380e4c0","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":764,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":764,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0212789179df4e6ca0000e3c23e44257"}},"80c5541bc989413486a05a63dbefc877":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9d04151b756f4f0fb3bdcf89a07cad34","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 764/764 [00:35&lt;00:00, 21.3B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dca4268d4a044b909f594cab25b01f5f"}},"e3f8726cab8347438ffb1dc97380e4c0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0212789179df4e6ca0000e3c23e44257":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9d04151b756f4f0fb3bdcf89a07cad34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dca4268d4a044b909f594cab25b01f5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7a1ebcd4ec9c46d5ae87dca458153d0a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2a7b7f8e56474e46b64f81476ae47e9d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_73b46d2545d141d19e1ff9b64224c74c","IPY_MODEL_b7a42baa898947bc8fe39f6bd114ed6c"]}},"2a7b7f8e56474e46b64f81476ae47e9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"73b46d2545d141d19e1ff9b64224c74c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_58e6c289bc024bc88bcba1cc0a456585","_dom_classes":[],"description":"Downloading:   7%","_model_name":"FloatProgressModel","bar_style":"","max":3247202234,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":214806528,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b22ef88cf4874ee991843661220b3e74"}},"b7a42baa898947bc8fe39f6bd114ed6c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4884fb263261439898cb134872c5dc33","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 215M/3.25G [00:20&lt;00:42, 71.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_77fe5031a689459490ed7c334c422a0c"}},"58e6c289bc024bc88bcba1cc0a456585":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b22ef88cf4874ee991843661220b3e74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4884fb263261439898cb134872c5dc33":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"77fe5031a689459490ed7c334c422a0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"hsFcTkg9MQdo"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BNXTqNRXnZHP","executionInfo":{"status":"ok","timestamp":1632247685428,"user_tz":240,"elapsed":215,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}},"outputId":"e304e40e-4816-43dc-f20c-e8eed84082af"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Sep 21 18:08:05 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   71C    P0    89W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"_N7rIdxuoqp0","colab":{"base_uri":"https://localhost:8080/","height":164},"executionInfo":{"status":"error","timestamp":1632246719590,"user_tz":240,"elapsed":230,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}},"outputId":"24a4d24b-771b-4c19-e95c-a3e2b9fef15f"},"source":["torch.cuda.empty_cache()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-18bf08814031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iRyKBfNc1-1E","executionInfo":{"status":"ok","timestamp":1632255240399,"user_tz":240,"elapsed":78,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}},"outputId":"ec96cf00-4610-4873-c6ea-41cfb9763f2a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VrRtdXbpNBq0","executionInfo":{"status":"ok","timestamp":1632247692894,"user_tz":240,"elapsed":3727,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}},"outputId":"73ac914e-7e04-4f2e-ac6c-ec5297d347b9"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.2)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.17)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"]}]},{"cell_type":"code","metadata":{"id":"uVcdCVLj2cTB"},"source":["# import json\n","# PATH = \"/content/drive/MyDrive/NLP/\"\n","# f = open(PATH + \"multiple_choice_92sim.json\",)\n","# data = json.load(f)\n","\n","# print(len(data))\n","# f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H7uPnMrfmiTu"},"source":["# import json\n","# PATH = \"/content/drive/MyDrive/Colab Notebooks/NLP/\"\n","# f = open(PATH + \"multiple_choice_92sim.json\",)\n","# data = json.load(f)\n","\n","# print(len(data))\n","# f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2cYajV6pXrWb"},"source":["# import json\n","# PATH = \"/content/drive/MyDrive/Colab Notebooks/NLP/\"\n","# f = open(PATH + \"labeled_pairs_3_15.json\",)\n","# data_2 = json.load(f)\n","\n","# print(len(data_2))\n","# f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b7_Zieqq2kN4","executionInfo":{"status":"ok","timestamp":1632255245242,"user_tz":240,"elapsed":581,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}}},"source":["from sklearn.model_selection import train_test_split"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"gs8GC-v93Roi"},"source":["# train_texts, test_texts = train_test_split(data, test_size=.1)\n","# with open(PATH + 'data/train.json', 'w') as f:\n","#   json.dump(train_texts, f)\n","\n","# with open(PATH + 'data/test.json', 'w') as f:\n","#   json.dump(test_texts, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WdJc44Zs3dEK"},"source":["# DATAPATH = PATH + 'data/train.json'\n","# def get_data(path=DATAPATH):\n","\n","#   question_list = list()\n","#   expo_list = list()\n","\n","#   with open(DATAPATH) as f:\n","#     data = list(json.load(f))\n","  \n","#   for question, expo in data:\n","#     question_list.append(question)\n","#     expo_list.append(expo[0])\n","\n","#   return question_list, expo_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eza55uv_dhKC","executionInfo":{"status":"ok","timestamp":1632255247053,"user_tz":240,"elapsed":71,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}}},"source":["import json\n","from tqdm.notebook import tqdm"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ta0M6FgVc8lL","executionInfo":{"status":"ok","timestamp":1632255247380,"user_tz":240,"elapsed":2,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}}},"source":["PATH = \"/content/drive/MyDrive/ReverseQA\"\n","DATAPATH = PATH + \"/processed_data/train.json\"\n","def get_data(path=DATAPATH):\n","\n","  question_list = list()\n","  answer_list = list()\n","\n","  with open(DATAPATH) as f:\n","    for line in f:\n","      data = json.loads(line)\n","      question_list.append(data['question'])\n","      answer_list.append(data['answer'])\n","\n","\n","  return question_list[0:1000], answer_list[0:1000]"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"5WlkZZ2k79Wk","executionInfo":{"status":"ok","timestamp":1632255247739,"user_tz":240,"elapsed":107,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}}},"source":["#DATAPATH = PATH + 'data/clean_train.json'\n","PATH = \"/content/drive/MyDrive/ReverseQA\"\n","DATAPATH = PATH + '/processed_data/valid_filtered_qa_pairs.json'\n","def get_data(path=DATAPATH):\n","\n","  question_list = list()\n","  expo_list = list()\n","\n","  with open(DATAPATH) as f:\n","    data = list(json.load(f))\n","    if [] in data:\n","      data.remove([])\n","  \n","  for question, expo in data:\n","    question_list.append(question)\n","    expo_list.append(expo[0])\n","\n","  return question_list[:100], expo_list[:100]"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"4v-Rshzt3fO8","executionInfo":{"status":"ok","timestamp":1632255250115,"user_tz":240,"elapsed":579,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}}},"source":["question_list, answer_list = get_data()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":120},"id":"NLh-ex868wqL","executionInfo":{"status":"ok","timestamp":1632254510967,"user_tz":240,"elapsed":74,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}},"outputId":"714003b4-209f-4e11-a7b6-51e307a35969"},"source":["answer_list[0]"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"Well, international JV and partnerships are incredibly important to our customers. They are a way to give a seamless experience to our customers, to get them around the world. This is one of those rare events that if they win, win, win; it's a win for United Airlines. It could be a win for our partners, and it's absolutely a win for our customers.\\nI think we -- and Star Alliance, we all believe that we have an opportunity to do better. We can be more seamlessly integrated with one another and that includes on the commercial front, but to a large degree, that includes the customer experience, where we can make the experience more seamless.\\nAnd we have a new CEO at Star Alliance, and that is his number one mission. I'll actually be going to the Star Alliance meeting on Mother's Day, which my wife doesn't appreciate, but it's in Germany. And the focus of the meeting is to talk about how we can create a more seamless experience for our customers and really have the focus to be on customers.\\nAnd we think there's a big opportunity there, and that's something that we'll be working on over the coming years. But our partnerships are really important, and we're looking forward to expanding partnerships, particularly in Latin America with Avianca and Copa, and we think there's a real opportunity. But we have strong partnerships across the Atlantic and Pacific. Adding Avianca, Copa and Azul to those relationships is going to give us the ability to give the American and LatAm a run for their money in Latin America.\""]},"metadata":{},"execution_count":40}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xYXImi5Y9jH7","executionInfo":{"status":"ok","timestamp":1632247581699,"user_tz":240,"elapsed":3971,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}},"outputId":"119c2341-398b-4a79-896f-b8b00d6bd3ea"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.2)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.2)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.17)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"]}]},{"cell_type":"code","metadata":{"id":"ki0lr_KC6TU2","executionInfo":{"status":"ok","timestamp":1632255254225,"user_tz":240,"elapsed":1372,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}}},"source":["import torch\n","import transformers\n","class IMDbDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels, length):\n","        self.encodings = encodings\n","        self.labels = labels\n","        self.length = length\n","\n","    def __getitem__(self, idx):\n","        encoding_item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        label_item = {key: torch.tensor(val[idx]) for key, val in self.labels.items()}\n","        return encoding_item, label_item\n","\n","    def __len__(self):\n","        return self.length\n","\n","def get_dataset(answer_list,question_list):\n","    from sklearn.model_selection import train_test_split\n","    #from transformers import BartTokenizerFast\n","    from transformers import BertTokenizer\n","\n","    train_es, val_es, train_qs, val_qs = train_test_split(answer_list,question_list, test_size=.1)\n","\n","    #tokenizer = BartTokenizerFast.from_pretrained('facebook/bart-base')\n","    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","\n","    train_q_encodings = tokenizer(train_qs, truncation=True, padding=True)\n","    val_q_encodings = tokenizer(val_qs, truncation=True, padding=True)\n","\n","    train_e_encodings = tokenizer(train_es, truncation=True, padding=True)\n","    val_e_encodings = tokenizer(val_es, truncation=True, padding=True)\n","\n","    train_dataset = IMDbDataset(train_e_encodings,train_q_encodings, length = len(train_qs))\n","    val_dataset = IMDbDataset(val_e_encodings, val_q_encodings, length=len(val_qs))\n","\n","    return train_dataset, val_dataset"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"YNtqQT9d6WYa","executionInfo":{"status":"ok","timestamp":1632255259250,"user_tz":240,"elapsed":5026,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}}},"source":["train_dataset, val_dataset = get_dataset(answer_list,question_list)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-R-6QB1uXHQe","executionInfo":{"status":"ok","timestamp":1632255259251,"user_tz":240,"elapsed":16,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}},"outputId":"02313335-3f13-4e92-b966-5baa661084ab"},"source":["print(len(train_dataset))"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["90\n"]}]},{"cell_type":"code","metadata":{"id":"6QteuqxY95sW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632255272870,"user_tz":240,"elapsed":8866,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}},"outputId":"b5fffe40-ad9c-44b6-88ac-7e9845f8102c"},"source":["import torch\n","from torch.nn import BCEWithLogitsLoss, BCELoss\n","\n","from torch.utils.data import DataLoader\n","#from transformers import BartForConditionalGeneration, AdamW\n","from transformers import AdamW\n","from transformers import BertGenerationEncoder, BertGenerationDecoder, BertTokenizer, EncoderDecoderModel\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(torch.cuda.is_available())\n","print(device)\n","\n","#model =  BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n","encoder = BertGenerationEncoder.from_pretrained('bert-base-uncased')\n","decoder = BertGenerationDecoder.from_pretrained('bert-base-uncased', add_cross_attention=True, is_decoder = True)\n","model = EncoderDecoderModel(encoder=encoder, decoder=decoder)\n","\n","model.to(device)\n","model.train()\n","\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n","\n","optim = AdamW(model.parameters(), lr=5e-5)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["You are using a model of type bert to instantiate a model of type bert-generation. This is not supported for all configurations of models and can yield errors.\n"]},{"output_type":"stream","name":"stdout","text":["True\n","cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertGenerationEncoder: ['cls.predictions.transform.dense.weight', 'bert.pooler.dense.bias', 'cls.predictions.decoder.weight', 'bert.embeddings.token_type_embeddings.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'bert.pooler.dense.weight']\n","- This IS expected if you are initializing BertGenerationEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertGenerationEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","You are using a model of type bert to instantiate a model of type bert-generation. This is not supported for all configurations of models and can yield errors.\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertGenerationDecoder: ['cls.predictions.transform.dense.weight', 'bert.pooler.dense.bias', 'cls.predictions.decoder.weight', 'bert.embeddings.token_type_embeddings.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'bert.pooler.dense.weight']\n","- This IS expected if you are initializing BertGenerationDecoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertGenerationDecoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertGenerationDecoder were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'lm_head.decoder.bias', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.value.weight', 'lm_head.decoder.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'lm_head.bias', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.key.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","metadata":{"id":"OVB2M129cSXL","executionInfo":{"status":"ok","timestamp":1632255272871,"user_tz":240,"elapsed":14,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}}},"source":["WEIGHT_PATH = PATH + '/weights/generation_clean_bert2'"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"fLgBN5BO-hny","executionInfo":{"status":"ok","timestamp":1632255279834,"user_tz":240,"elapsed":70,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}}},"source":["def train(epochs=10):\n","    train_loss_set = list()\n","    for epoch in tqdm(range(epochs)):\n","        for batch in train_loader:\n","            input, label = batch\n","\n","            optim.zero_grad()\n","\n","            input_ids = input['input_ids'].to(device)\n","            attention_mask = input['attention_mask'].to(device)\n","\n","            labels = label['input_ids'].to(device)\n","            outputs = model(input_ids = input_ids, attention_mask=attention_mask, decoder_input_ids=labels, labels=labels)\n","            loss = outputs[0]\n","            # loss_func = BCEWithLogitsLoss()\n","            # loss = loss_func(logits, labels)  # convert labels to float for calculation\n","            # loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n","            train_loss_set.append(loss.item())\n","\n","            # Backward pass\n","            loss.backward()\n","\n","            optim.step()\n","\n","        print(\"Finished epoch {}\".format(epoch))\n","\n","    model.save_pretrained(WEIGHT_PATH)\n","    return train_loss_set"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":637,"referenced_widgets":["28a674e210df4e2fb759dcd282458290","8a371a3be7bc41aab7b2855eafdb6125","e120e8b1459d4152b4a9a6e77bbc9b26","8ff48795ef8343d98da8c65e4d5df0e7","7f179d157d5144468e115b2ce995cea6","736effb3fd8943e0823eedac3be77ba0","2a43df6a77ba40878c23cd35fdee4f5f","dcdea7fa0166432484a31580b8e79bc1","a0eb35fcc6b04807a5dfcb45cb0a1483","7e07e672d47d40d6a5fb43ed6bd02887","8b4191948b584b588f20f374691e0e1e"]},"id":"GIHaHiPJ_Om5","executionInfo":{"status":"ok","timestamp":1632256103948,"user_tz":240,"elapsed":620458,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}},"outputId":"4fc2a51d-2e3f-4a46-cc93-c845520cd11c"},"source":["loss_values = train(20)\n","\n","import matplotlib.pyplot as plt\n","\n","plt.plot(loss_values)\n","plt.show()"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"28a674e210df4e2fb759dcd282458290","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Finished epoch 0\n","Finished epoch 1\n","Finished epoch 2\n","Finished epoch 3\n","Finished epoch 4\n","Finished epoch 5\n","Finished epoch 6\n","Finished epoch 7\n","Finished epoch 8\n","Finished epoch 9\n","Finished epoch 10\n","Finished epoch 11\n","Finished epoch 12\n","Finished epoch 13\n","Finished epoch 14\n","Finished epoch 15\n","Finished epoch 16\n","Finished epoch 17\n","Finished epoch 18\n","Finished epoch 19\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"MEV8frBYpWwe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632256120833,"user_tz":240,"elapsed":11255,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}},"outputId":"5ec4c744-cd5e-442d-c2a5-20902d976d93"},"source":["#model = BartForConditionalGeneration.from_pretrained(WEIGHT_PATH)\n","model = EncoderDecoderModel.from_pretrained(WEIGHT_PATH)\n","model.to(device)"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["EncoderDecoderModel(\n","  (encoder): BertGenerationEncoder(\n","    (embeddings): BertGenerationEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (decoder): BertGenerationDecoder(\n","    (bert): BertGenerationEncoder(\n","      (embeddings): BertGenerationEmbeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (lm_head): BertGenerationOnlyLMHead(\n","      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"mc4mkS4FhOkI","executionInfo":{"status":"ok","timestamp":1632256128023,"user_tz":240,"elapsed":1276,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}}},"source":["#DATAPATH = PATH + 'data/clean_test.json'\n","DATAPATH = PATH + \"/processed_data/test.json\"\n","import torch\n","#from transformers import BartTokenizerFast\n","#tokenizer = BartTokenizerFast.from_pretrained('facebook/bart-base')\n","from transformers import BertTokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","def get_data(path=DATAPATH):\n","\n","  question_list = list()\n","  answer_list = list()\n","\n","  with open(DATAPATH) as f:\n","    for line in f:\n","      data = json.loads(line)\n","      question_list.append(data['question'])\n","      answer_list.append(data['answer'])\n","\n","\n","  return question_list[0:200], answer_list[0:200]\n","class TestDataset(torch.utils.data.Dataset):\n","  def __init__(self, encodings, expos, labels, length):\n","      self.encodings = encodings\n","      self.expos = expos\n","      self.labels = labels\n","      self.length = length\n","\n","  def __getitem__(self, idx):\n","      encoding_item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","      return (encoding_item, self.labels[idx], self.expos[idx])\n","\n","  def __len__(self):\n","      return self.length\n","\n","def get_dataset(question_list, expo_list):\n","\n","  expo_encodings = tokenizer(expo_list, truncation=True, padding=True)\n","\n","  test_dataset = TestDataset(expo_encodings, expo_list, question_list,length = len(question_list))\n","\n","  return test_dataset"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"44uHhJi9iVZe","executionInfo":{"status":"ok","timestamp":1632256131272,"user_tz":240,"elapsed":795,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}}},"source":["question_list, expo_list = get_data()\n","test_dataset = get_dataset(question_list, expo_list)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_WXxEEU5x-IG","executionInfo":{"status":"ok","timestamp":1632253715872,"user_tz":240,"elapsed":3878,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}},"outputId":"69380cde-5a04-4887-a043-246f93cd011f"},"source":["!pip install datasets"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.12.1)\n","Requirement already satisfied: huggingface-hub<0.1.0,>=0.0.14 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.17)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.8.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.7.4.post0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.8.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.2)\n","Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets) (3.7.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets) (3.0.12)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.6.3)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (5.1.0)\n","Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (3.0.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ka7UqsS8y7of","executionInfo":{"status":"ok","timestamp":1632247366042,"user_tz":240,"elapsed":3793,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}},"outputId":"887b1693-14f8-4ab9-eabe-b4624c36a0c7"},"source":["!pip install bert_score"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: bert_score in /usr/local/lib/python3.7/dist-packages (0.3.10)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from bert_score) (1.9.0+cu102)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from bert_score) (3.2.2)\n","Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.7/dist-packages (from bert_score) (4.62.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bert_score) (2.23.0)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from bert_score) (1.1.5)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from bert_score) (21.0)\n","Requirement already satisfied: transformers>=3.0.0numpy in /usr/local/lib/python3.7/dist-packages (from bert_score) (4.10.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->bert_score) (2.4.7)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert_score) (1.19.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert_score) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert_score) (1.15.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->bert_score) (3.7.4.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (5.4.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (0.0.45)\n","Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (0.0.17)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (0.10.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (4.8.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (3.0.12)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.0.0numpy->bert_score) (3.5.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert_score) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert_score) (1.3.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (1.24.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.0numpy->bert_score) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.0numpy->bert_score) (7.1.2)\n"]}]},{"cell_type":"code","metadata":{"id":"mcidwQRAG6Co"},"source":["#from transformers import datasets\n","from datasets import load_metric \n","metric = load_metric(\"bertscore\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VW6KipLJbq7j","executionInfo":{"status":"ok","timestamp":1632256137881,"user_tz":240,"elapsed":64,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}}},"source":["#from transformers import BartForConditionalGeneration\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","from torch.utils.data import DataLoader\n","from tqdm.notebook import tqdm\n","\n","def validate(val_dataset):\n","    #model =  BartForConditionalGeneration.from_pretrained(WEIGHT_PATH)\n","    model = EncoderDecoderModel.from_pretrained(WEIGHT_PATH)\n","    model.to(device)\n","    model.eval()\n","\n","    val_loader = DataLoader(val_dataset, batch_size=5, shuffle=True)\n","\n","    print(\"Evaluating on {} questions\".format(len(val_dataset)))\n","\n","    list_of_references = list()\n","    list_of_hypotheses = list()\n","    list_of_original = list()\n","    list_of_pp = list()\n","\n","    count = 0\n","    for batch in val_loader:\n","        input, label, orig = batch\n","        input_ids = input['input_ids'].to(device)\n","        attention_mask = input['attention_mask'].to(device)\n","\n","        with torch.no_grad():\n","            output = model.generate(\n","                #decoder_input_ids=decoder_input_ids,\n","                input_ids=input_ids,\n","                # do_sample=True,\n","                # max_length=600,\n","                # temperature=1.0,\n","                # top_k=5,\n","                # top_p=0.9,\n","                # repetition_penalty=1.0,\n","                )\n","            #print(generated_sequences)\n","            #print(label)\n","            reference = label[0].split()\n","\n","            text = tokenizer.decode(output[0], clean_up_tokenization_spaces=True)\n","            #hypothesis = text.split()\n","            '''\n","            if text != '</s>' or text != '<s>' or text != '<pad>':\n","              hypothesis += text\n","            '''\n","            text = text.replace('</s>', '')\n","            text = text.replace('<s>', '')\n","            text = text.replace('<pad>', '')\n","\n","            hypothesis = text.split()\n","            #print(text)\n","\n","            #perplexity\n","            # token = tokenizer(text, return_tensors='pt')\n","            # ppl = get_ppl(token)\n","\n","            #print(pp_score)\n","            # list_of_pp.append(ppl)\n","            # Prints out sequences\n","            #print(hypothesis)\n","\n","            list_of_hypotheses.append(hypothesis)\n","            list_of_references.append([reference])\n","            list_of_original.append(orig)\n","        print(count)\n","        count += 1\n","            \n","    # Calculate BLEU Score\n","    import nltk\n","    score = nltk.translate.bleu_score.corpus_bleu(list_of_references, list_of_hypotheses)\n","\n","    return list_of_references, list_of_hypotheses,list_of_original, score, list_of_pp\n","      # import torchtext\n","\n","      #   score = torchtext.data.metrics.bleu_score(candidate_corpus, references_corpus)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"nF_dljZt8pkz","executionInfo":{"status":"ok","timestamp":1632256139124,"user_tz":240,"elapsed":83,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}}},"source":["def get_ppl(encodings):\n","  max_length = 600\n","  stride = 300\n","\n","  lls = []\n","  for i in range(0, encodings.input_ids.size(1), stride):\n","      begin_loc = max(i + stride - max_length, 0)\n","      end_loc = min(i + stride, encodings.input_ids.size(1))\n","      trg_len = end_loc - i    # may be different from stride on last loop\n","      input_ids = encodings.input_ids[:,begin_loc:end_loc].to(device)\n","      target_ids = input_ids.clone()\n","      target_ids[:,:-trg_len] = -100\n","\n","      with torch.no_grad():\n","          outputs = model(input_ids, labels=target_ids)\n","          log_likelihood = outputs[0] * trg_len\n","\n","      lls.append(log_likelihood)\n","\n","  ppl = torch.exp(torch.stack(lls).sum() / end_loc)\n","  return ppl"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yM7PM1XyAVbw","executionInfo":{"status":"ok","timestamp":1632256183357,"user_tz":240,"elapsed":42982,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}},"outputId":"a0a6e0f6-44cc-4aec-df87-9a2348cffeef"},"source":["list_of_references, list_of_hypotheses, list_of_original, score, list_of_pp = validate(test_dataset)"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluating on 200 questions\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DIBv_ONGB_y7","executionInfo":{"status":"ok","timestamp":1632247377425,"user_tz":240,"elapsed":17,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}},"outputId":"352200fa-ac6b-414b-8edd-76398e0ed1f3"},"source":["print(len(list_of_pp))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n"]}]},{"cell_type":"code","metadata":{"id":"PPSHBimK5wXN","executionInfo":{"status":"ok","timestamp":1632256188068,"user_tz":240,"elapsed":82,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}}},"source":["from pprint import pprint"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mHXWYQOp5OAv","executionInfo":{"status":"ok","timestamp":1632256188511,"user_tz":240,"elapsed":112,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}},"outputId":"1c45859a-d3a9-4881-a985-a38b736974cc"},"source":["#list_of_references, list_of_hypotheses, list_of_original, score, list_of_pp = validate(test_dataset)\n","for i in range(0,10):\n","  pprint(list_of_references[i][0])\n","  print('------------------------------------------------')\n","  pprint(list_of_hypotheses[i])\n","  print('------------------------------------------------')\n","  pprint(list_of_original[i])\n","  print(\"================================================\")"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["['Okay.',\n"," 'And',\n"," 'then,',\n"," 'finally,',\n"," 'John,',\n"," 'in',\n"," 'the',\n"," 'press',\n"," 'release',\n"," 'you',\n"," 'mentioned',\n"," 'Okay.',\n"," 'And',\n"," 'finally',\n"," 'John,',\n"," 'in',\n"," 'the',\n"," 'press',\n"," 'release',\n"," 'you',\n"," 'mentioned',\n"," 'kind',\n"," 'of',\n"," 'a',\n"," 'reorganization',\n"," 'of',\n"," 'some',\n"," 'international',\n"," 'offices',\n"," 'that',\n"," 'you',\n"," 'had.']\n","------------------------------------------------\n","['[unused1]',\n"," 'i',\n"," 'think',\n"," 'you',\n"," 'could',\n"," 'to',\n"," 'be',\n"," 'a',\n"," 'little',\n"," 'bit',\n"," 'of',\n"," 'the',\n"," 'year,',\n"," 'i',\n"," 'think',\n"," 'you',\n"," 'could',\n"," 'talk',\n"," 'about']\n","------------------------------------------------\n","('Yes.',\n"," \"Well, we have our own – it's hard to answer that, specifically. If you're \"\n"," 'asking that is the exact changes and exact spacing going from a Gen 4 in the '\n"," 'Marcellus to a Gen 5 in the Marcellus, is that going to transfer to the '\n"," 'Eagle Ford? And is the fluid pumped in a Gen 4 Marcellus to a Gen 5 '\n"," 'Marcellus, is that the exact fluid that we pump going to transfer to the '\n"," 'Eagle Ford? The answer to that is no. But the concept of being able to save '\n"," 'money with the spacing changes in the Marcellus and the transfer of fluid '\n"," 'pumped and the more clusters per stage by having a little wider spacing, we '\n"," \"do take all of that in consideration in the tweaking that's going on in the \"\n"," 'Eagle Ford.',\n"," 'Sure, Jeffrey. So as a shipper on that project, we do communicate quite a '\n"," 'bit with the operator and the other partners. The New Jersey denial was not '\n"," 'unexpected. They realized that there was insufficient data that was '\n"," 'necessary and required. And quite frankly they were moving toward that end '\n"," 'when we lost the FERC quorum. As you know, PennEast is still pending their '\n"," 'certificate. But in this law, I guess what I understand is they move more '\n"," 'toward the complete application at this point, and it will get a second '\n"," 'look.',\n"," 'Can you repeat your question again, I missed the first part.',\n"," \"I think it's plausible that we'll have a lot of data that would give the \"\n"," 'likelihood that we could.')\n","================================================\n","['Okay,',\n"," 'okay.',\n"," 'Thank',\n"," 'you',\n"," 'for',\n"," 'the',\n"," 'clarification.',\n"," 'Appreciate',\n"," 'it.',\n"," 'And',\n"," 'then',\n"," 'Asia-Pac',\n"," 'seemed',\n"," 'to',\n"," 'show',\n"," 'up',\n"," 'as',\n"," 'a',\n"," 'notably',\n"," 'strong',\n"," 'geography',\n"," 'in',\n"," 'this',\n"," 'quarter,',\n"," 'is',\n"," 'there',\n"," 'anything',\n"," 'there',\n"," 'that',\n"," 'we',\n"," 'should',\n"," 'be',\n"," 'aware',\n"," 'of',\n"," 'is',\n"," 'there',\n"," 'or',\n"," 'is',\n"," 'that',\n"," 'just',\n"," 'kind',\n"," 'of',\n"," 'noise',\n"," 'in',\n"," 'the',\n"," 'numbers?']\n","------------------------------------------------\n","['[unused1]',\n"," 'i',\n"," 'think',\n"," 'you',\n"," 'could',\n"," 'to',\n"," 'be',\n"," 'a',\n"," 'little',\n"," 'bit',\n"," 'of',\n"," 'the',\n"," 'year,',\n"," 'i',\n"," 'think',\n"," 'you',\n"," 'could',\n"," 'talk',\n"," 'about']\n","------------------------------------------------\n","('Yes, I mean, we continue to see strong growth in Asia and for the quarter, '\n"," 'the growth, if you look across the business groups, it was mainly in most of '\n"," 'the revenue upside for the second half is in Verification and IP and that’s '\n"," 'merely because those segments benefit from upfront revenue recognition on '\n"," 'delivery of the IP and hardware. We had strength across all product lines.',\n"," 'Hello, Brian.',\n"," \"Yeah. A couple of ways. One, our Eagle Ford has improved as you've seen with \"\n"," 'the deck we just went through, our efficiency, our cost of business, cost of '\n"," 'operations, the return that we are able to deliver and the strip pricing '\n"," \"that we have out there right now. We're getting good returns in our Eagle \"\n"," 'Ford operation. Now, those returns do not compete with our Marcellus '\n"," 'operation.',\n"," 'Yes, that’s a good clarification, Sterling. Yes, revenue contribution from '\n"," 'Palladium and the cloud would be ratable, yes.',\n"," 'Thanks, Mike.')\n","================================================\n","['Hey', 'guys.', 'Can', 'you', 'hear', 'me', 'okay?']\n","------------------------------------------------\n","['[unused1]',\n"," 'i',\n"," 'think',\n"," 'you',\n"," 'could',\n"," 'to',\n"," 'be',\n"," 'a',\n"," 'little',\n"," 'bit',\n"," 'of',\n"," 'the',\n"," 'year,',\n"," 'i',\n"," 'think',\n"," 'you',\n"," 'could',\n"," 'talk',\n"," 'about']\n","------------------------------------------------\n","('Yes.',\n"," \"But you're right. I don't want to be coy on the exploration ideas. But as \"\n"," \"you appreciate in your – the way you catch the question, we're just not \"\n"," \"going to talk in-depth about specifics of what we're doing. But I do \"\n"," \"appreciate the question regarding kind of our thought process on what we're \"\n"," 'trying to achieve.',\n"," 'Yes. Sure Rich. Yes purchase accounting rules significantly limit the '\n"," \"revenue we can recognize from both AWR and Integrand in 2020. Combined we've \"\n"," 'added $20 million to annual revenue in our guidance for 2020. Almost all of '\n"," 'that from AWR. We expect both acquisitions to be dilutive to earnings in '\n"," '2020, but we expect them to be accretive in 2021.',\n"," 'Yes. Good question. I think, Japan is important market for us. A couple '\n"," 'areas Japan is very strong, and I’ll just name a few. Now, automotive, they '\n"," 'are very, very strong. And also, I mentioned earlier the edge industrial '\n"," \"IoT, the microcontroller. And there's a lot of controller collecting data, \"\n"," \"and then, couple of key prayer in Japan that we're very excited to team up \"\n"," 'with them. And also, the whole video surveillance, consumer related areas, '\n"," 'and that AI machine learning can really play a role in it. And so, I think, '\n"," 'this is a very important market, and then they are recovering very nicely. '\n"," 'And then, right now, we’re engaging heavily with a couple of key customer '\n"," 'that we want to be that trusted partner going forward.',\n"," 'Thank you Michael.')\n","================================================\n","['Great.',\n"," 'Thank',\n"," 'you.',\n"," 'And',\n"," 'one',\n"," 'quick',\n"," 'one',\n"," 'and',\n"," 'I',\n"," 'apologize',\n"," 'if',\n"," 'you',\n"," 'said',\n"," 'this',\n"," 'earlier.',\n"," 'But',\n"," 'with',\n"," 'regards',\n"," 'to',\n"," 'the',\n"," 'exploratory',\n"," 'areas,',\n"," 'can',\n"," 'you',\n"," 'say',\n"," 'whether',\n"," 'you',\n"," 'are',\n"," 'looking',\n"," 'for',\n"," 'or',\n"," 'whether',\n"," 'your',\n"," 'expectations',\n"," 'are',\n"," 'for',\n"," 'oil,',\n"," 'dry',\n"," 'gas',\n"," 'or',\n"," 'liquids-rich',\n"," 'gas?']\n","------------------------------------------------\n","['[unused1]',\n"," 'i',\n"," 'think',\n"," 'you',\n"," 'could',\n"," 'to',\n"," 'be',\n"," 'a',\n"," 'little',\n"," 'bit',\n"," 'of',\n"," 'the',\n"," 'year,',\n"," 'i',\n"," 'think',\n"," 'you',\n"," 'could',\n"," 'talk',\n"," 'about']\n","------------------------------------------------\n","('Yeah. What I had indicated, Brian, was that our focus again, one, two, and '\n"," 'three was just on a return, that we were indifferent on the commodity. At '\n"," \"this stage, it's looking at, like, that our focus is going to be oil at this \"\n"," 'time though, where these ideas have floated to the top.',\n"," \"Yes, Mike, I'm not going to get down that granular. We have described \"\n"," \"exactly what you just laid out, that we're looking to improve our lie. We're \"\n"," \"looking to be able to find projects that would enhance the shareholders' \"\n"," \"value. And we think that from an Eagle Ford position-type asset, I don't \"\n"," 'consider that level of return as core. I do define our Marcellus that you '\n"," \"laid out as core and we're just trying to again improve our efficiency and \"\n"," \"look at a project that would allow us to do what I've said in the past and \"\n"," \"that's be able to grow the asset and generate free cash. So you're going to \"\n"," \"be in a good return ZIP Code if you're able to accomplish that.\",\n"," 'Yes, I would expect non-GAAP gross margin to return to more typical levels '\n"," 'in the second half of the year. And then the reason we expect operating '\n"," 'margins to be 30% is because we are investing in new employees as we invest '\n"," 'in opportunities to expand our business with market-shaping customers and '\n"," 'the TAM expansion opportunities we have and also because the annual pay '\n"," 'increases for employees were effective in July.',\n"," \"And John, it's John Wall here. You'll see some revenue mix by geography \"\n"," \"information on page four of our CFO commentary. On that you'll see that Asia \"\n"," 'ticked up to 28% for 2018. Of that 28%, just under 10% of that was from '\n"," 'China. I know you asked that in the last call.',\n"," 'Yes.')\n","================================================\n","['Hey',\n"," 'guys.',\n"," 'Thanks',\n"," 'for',\n"," 'taking',\n"," 'my',\n"," 'question.',\n"," 'Just',\n"," 'to',\n"," 'follow-up',\n"," 'on',\n"," 'that',\n"," 'China',\n"," 'argument.',\n"," 'So',\n"," 'it’s',\n"," 'up',\n"," 'to',\n"," '12%',\n"," 'of',\n"," 'our',\n"," 'revenue',\n"," 'today',\n"," 'versus',\n"," 'a',\n"," 'year',\n"," 'ago,',\n"," '8%,',\n"," 'it',\n"," 'was',\n"," 'kind',\n"," 'of',\n"," 'trending',\n"," 'between',\n"," '8%',\n"," 'and',\n"," '10%',\n"," 'except',\n"," 'for',\n"," 'the',\n"," 'Q4',\n"," 'which',\n"," 'probably',\n"," 'was',\n"," 'hardware',\n"," 'heavy.']\n","------------------------------------------------\n","['[unused1]',\n"," 'i',\n"," 'think',\n"," 'you',\n"," 'could',\n"," 'just',\n"," 'just',\n"," 'just',\n"," 'to',\n"," 'be',\n"," 'a',\n"," 'little',\n"," 'bit',\n"," 'of',\n"," 'the',\n"," 'year,',\n"," 'i',\n"," 'think',\n"," 'you']\n","------------------------------------------------\n","('Sure. Like you say, I mean, our China revenue mix over the past five '\n"," 'quarters has ranged below 8% in Q2, 18% to high of 13% in Q4 2018. Well, I '\n"," 'am not inclined to attribute motivation. Our China business has been strong '\n"," 'over the past several quarters, but for now our ability to deliver products '\n"," 'and services to certain customers that are on the BIS entity list is '\n"," 'limited. So we’d expect the percentage of revenue in China to be lower for '\n"," 'the second half of fiscal 2019 than the first half.',\n"," 'Thanks, John.',\n"," 'I guess, Sterling, I mean..',\n"," 'Yes.',\n"," 'Hey, Charles.')\n","================================================\n","['Thank', 'you', 'so', 'much.']\n","------------------------------------------------\n","['[unused1]',\n"," 'i',\n"," 'think',\n"," 'you',\n"," 'could',\n"," 'to',\n"," 'be',\n"," 'a',\n"," 'little',\n"," 'bit',\n"," 'of',\n"," 'the',\n"," 'year,',\n"," 'i',\n"," 'think',\n"," 'you',\n"," 'could',\n"," 'talk',\n"," 'about']\n","------------------------------------------------\n","('Thank you.',\n"," \"And Mitch, in relation to your question with regard to what's included in \"\n"," 'guidance for 2019, I mean, 2018 was a very strong year for functional '\n"," 'verification. And of course, it benefited from that shift of hardware '\n"," 'revenue that we were originally expecting to deliver in 2019 and we '\n"," \"delivered it in 2018. So that's going to make 2019 and tough compare for \"\n"," 'functional verification.',\n"," 'Yes, and then, we are not going to speculate in terms of how that plays out '\n"," 'for next year. But you are correct in your assessment that in some cases for '\n"," 'some customers we had revenue in the first half of the year and some – and '\n"," 'the second half of the year is quite different and we do have some '\n"," 'headwinds. If there is no change, those headwinds will persist into next '\n"," 'year.',\n"," 'Yeah. On all of that, we have seismic. We do plan on shooting additional '\n"," \"seismic. We have control points, subsurface control points that we've \"\n"," 'incorporated into our interpretation. And the initial process would involve '\n"," 'a combination of both verticals to gather core data. And then probably a '\n"," 'short lateral to evaluate the section a little bit more thoroughly. So, '\n"," 'yeah, and all of that is included within our capital program.',\n"," \"Marshall, I don't put the core definition as only what our return is in the \"\n"," 'Marcellus. There are some areas out there that I think have what I would '\n"," 'define as core returns that might not be the returns of the Marcellus, but '\n"," \"they're returns, if that was where you were strictly focused would allow \"\n"," 'for, even though less returns than the Marcellus, would still allow for '\n"," 'growth and return of free cash, and that is somewhere in between, which I '\n"," 'have not defined, between our Eagle Ford and our Marcellus.')\n","================================================\n","['The',\n"," 'impact',\n"," 'of',\n"," 'taxes',\n"," 'going',\n"," 'forward,',\n"," 'just',\n"," 'wanted',\n"," 'if',\n"," 'there',\n"," 'is',\n"," 'something',\n"," 'you',\n"," 'can',\n"," 'say',\n"," 'on',\n"," 'that?']\n","------------------------------------------------\n","['[unused1]',\n"," 'i',\n"," 'think',\n"," 'you',\n"," 'could',\n"," 'to',\n"," 'be',\n"," 'a',\n"," 'little',\n"," 'bit',\n"," 'of',\n"," 'the',\n"," 'year,',\n"," 'i',\n"," 'think',\n"," 'you',\n"," 'could',\n"," 'talk',\n"," 'about']\n","------------------------------------------------\n","(\"Yes, I mean that's a GAAP only thing. I mean in October 2019, we initiated a \"\n"," 'series of transactions involving an internal realignment of our '\n"," 'international operating structure. And that realignment may significantly '\n"," 'increase our foreign deferred tax assets. As you know, deferred tax assets '\n"," 'are recognized when the depreciation of the asset is expected to offset '\n"," 'future profits.',\n"," 'Thank you.',\n"," 'Hi, Holly.',\n"," 'Yes, thanks, David.',\n"," 'Yes, so reaching way back to when we press released the deal, we let '\n"," 'everyone know that it was a Henry Hub-based price that had other '\n"," 'opportunities associated with it. Due to the confidentiality with Sumitomo, '\n"," \"we've hesitated and not disclosed any particulars about the pricing.\")\n","================================================\n","['Okay.',\n"," 'And',\n"," 'then',\n"," 'as',\n"," 'far',\n"," 'as',\n"," 'IP',\n"," 'revenue',\n"," 'for',\n"," 'the',\n"," 'quarter,',\n"," 'I',\n"," 'mean,',\n"," 'you',\n"," 'guys',\n"," 'did',\n"," 'post',\n"," 'strong',\n"," 'quarter.',\n"," 'I',\n"," 'mean,',\n"," 'how',\n"," 'should',\n"," 'we',\n"," 'think',\n"," 'about',\n"," 'IP',\n"," 'as',\n"," 'a',\n"," 'whole',\n"," 'growth',\n"," 'wise',\n"," 'for',\n"," 'the',\n"," 'full-year?']\n","------------------------------------------------\n","['[unused1]',\n"," 'i',\n"," 'think',\n"," 'you',\n"," 'could',\n"," 'to',\n"," 'be',\n"," 'a',\n"," 'little',\n"," 'bit',\n"," 'of',\n"," 'the',\n"," 'year,',\n"," 'i',\n"," 'think',\n"," 'you',\n"," 'could',\n"," 'be',\n"," 'about']\n","------------------------------------------------\n","(\"We're very pleased with our IP results in Q1. But IP in Q1 benefits from a \"\n"," \"relatively easy compare versus Q1 2018. We're not guiding the individual \"\n"," \"product groups, but we're very pleased with our with our IP results for the \"\n"," 'first quarter.',\n"," 'Thank you.',\n"," 'Sure Rich, yeah, I mean for – let me see, for functional verification it was '\n"," 'high teens that for – actually high teens for functional verification and '\n"," 'mid to high teens for IP for the year in 2018. Let me see for the – and then '\n"," 'in relation to next year. I think the key thing to point out here is that '\n"," \"we've pretty much an inline quarter for Q4 with the addition of that \"\n"," \"hardware shift that came out of '19 into '18. So therefore for '19, I think \"\n"," \"the knock on impact there is, we think it's a tough compare for functional \"\n"," 'verification. But we think the rest of the businesses should all perform '\n"," 'strongly to get us to average at 7%.',\n"," 'Okay, thanks.',\n"," 'Sorry, can you repeat the question?')\n","================================================\n","['Got',\n"," 'it.',\n"," 'Thank',\n"," 'you.',\n"," \"That's\",\n"," 'very',\n"," 'helpful',\n"," 'color.',\n"," 'And',\n"," 'then',\n"," 'I',\n"," 'guess',\n"," 'sort',\n"," 'of',\n"," 'subsequent',\n"," 'to',\n"," 'that,',\n"," 'if',\n"," 'you',\n"," 'could',\n"," 'discuss',\n"," 'your',\n"," '–',\n"," 'obviously,',\n"," 'this',\n"," 'production',\n"," 'growth',\n"," 'this',\n"," 'year,',\n"," 'the',\n"," 'rates,',\n"," 'just',\n"," 'getting',\n"," 'done',\n"," 'with',\n"," 'the',\n"," 'one',\n"," 'rig,',\n"," 'one',\n"," 'completion',\n"," 'crew',\n"," 'plan.',\n"," 'Can',\n"," 'you',\n"," 'sort',\n"," 'of',\n"," 'discuss',\n"," 'how',\n"," 'the',\n"," 'company',\n"," 'plans',\n"," 'to',\n"," 'add',\n"," 'either',\n"," 'rigs',\n"," 'or',\n"," 'more',\n"," 'completion',\n"," 'crews',\n"," 'into',\n"," 'and',\n"," 'through',\n"," 'early',\n"," '2018',\n"," 'as',\n"," 'Sunrise',\n"," 'and',\n"," 'the',\n"," 'rest',\n"," 'of',\n"," 'the',\n"," 'power,',\n"," 'Orion,',\n"," 'and',\n"," 'other',\n"," 'projects',\n"," 'come',\n"," 'on',\n"," 'line?']\n","------------------------------------------------\n","['[unused1]',\n"," 'so',\n"," 'i',\n"," 'think,',\n"," 'i',\n"," 'think',\n"," 'you',\n"," 'could',\n"," 'think',\n"," 'to',\n"," 'be',\n"," 'the',\n"," 'guidance',\n"," 'to',\n"," 'the',\n"," 'year,',\n"," 'i',\n"," 'think']\n","------------------------------------------------\n","(\"Yeah. We do plan in 2018 that we'll most likely just be adding a rig and a \"\n"," \"frac rig. That's all that's going to be necessary to grow into the new \"\n"," 'capacity. And then the 2018 program, when you look at outside of the '\n"," 'Marcellus, the 2018 program is going to take in consideration not only where '\n"," 'we are with our Eagle Ford. And again, the gaining efficiencies in return '\n"," 'that we see there, but it will certainly be augmented with new data coming '\n"," \"from our couple of areas of testing that we're going to do during 2017.\",\n"," \"Yeah. It's quite diversified. But yeah, we went through a period back in \"\n"," '2016 where we refocused our IP and went for profitable revenue growth. Right '\n"," \"now we're only guiding Q1 and the year. But certainly IP has been doing \"\n"," \"very, very well. We're very pleased with the growth that we're seeing.\",\n"," 'Yes Mitch. We can hear you.',\n"," 'Hey, Phillip.',\n"," 'Well, we are not guiding out beyond 2019, everything we know is included in '\n"," 'our guidance for 2019. We take a longer term view over things again with a '\n"," 'focus on any one quarter, I tend to – like compare current results against '\n"," 'our current midpoint of guidance against 2016, and I think I would expect '\n"," 'the model to be pretty consistent.')\n","================================================\n","[\"I'm\",\n"," 'well.',\n"," 'Thank',\n"," 'you.',\n"," \"There's\",\n"," 'a',\n"," 'view',\n"," 'that',\n"," 'NIPA',\n"," 'growth',\n"," 'is',\n"," 'somewhat',\n"," 'finite',\n"," 'near',\n"," 'term',\n"," 'until',\n"," 'these',\n"," 'capacity',\n"," 'expansions',\n"," 'come',\n"," 'on',\n"," 'line',\n"," 'but',\n"," 'the',\n"," 'guidance',\n"," 'raise',\n"," 'would',\n"," 'indicate',\n"," 'production,',\n"," 'including',\n"," \"Cabot's,\",\n"," 'can',\n"," 'grow',\n"," 'prior',\n"," 'to',\n"," 'that',\n"," 'and',\n"," 'local',\n"," 'pricing',\n"," 'likely',\n"," 'remains',\n"," 'supportive',\n"," 'given',\n"," 'the',\n"," 'current',\n"," 'bound',\n"," 'storage',\n"," 'levels',\n"," 'and',\n"," 'then,',\n"," 'of',\n"," 'course,',\n"," 'the',\n"," 'evacuation',\n"," 'on',\n"," 'the',\n"," 'horizon.']\n","------------------------------------------------\n","['[unused1]',\n"," 'i',\n"," 'think',\n"," 'you',\n"," 'could',\n"," 'to',\n"," 'be',\n"," 'a',\n"," 'little',\n"," 'bit',\n"," 'of',\n"," 'the',\n"," 'year,',\n"," 'i',\n"," 'think',\n"," 'you',\n"," 'could',\n"," 'be',\n"," 'about']\n","------------------------------------------------\n","(\"Yeah, I will – we do have a slide out there that has – I'm thinking we had a \"\n"," 'slide in one of our presentations that had the market share and our '\n"," \"percentage contribution to each indices, but I'll let Jeff handle the other \"\n"," 'question.',\n"," 'No, we are right now have – we have four wells in one area and the four '\n"," 'wells that we have in the one area is the area that we had less subsurface '\n"," \"control points to be able to mature our concept. And so we're gathering \"\n"," 'additional data there. One well in the other area, in this other area, we '\n"," 'had and have more subsurface information and we have more information to '\n"," 'mature our concept up front in that area, but the drilling of the well would '\n"," 'assist us in proof of concept on some of our ideas.',\n"," 'Yes. The profile is the profitability profile is very similar to EDA. And '\n"," \"it's probably our entry into system analysis is probably one of our drivers \"\n"," 'of increased op margin. I think if you look at our gross margin for 2018 it '\n"," \"was 90%. In 2019 we achieved 90.6%. And in our guidance we're targeting 91% \"\n"," \"because of the growth we're seeing and because of all the evaluations that \"\n"," 'are underway on the system analysis space.',\n"," 'The only wells that are down today are wells that have been drilled '\n"," 'subsequent to us getting into the area, and that was typically wells drilled '\n"," 'years and years and years ago.',\n"," 'Yes, Drew, I would think that – I would be surprised if it goes beyond 12 '\n"," 'months that we would not be able to rationalize with a fairly high degree of '\n"," 'confidence where in our return profile expectations that these two projects '\n"," 'would fall.')\n","================================================\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EhUGiIV2RTbO","executionInfo":{"status":"ok","timestamp":1632256300136,"user_tz":240,"elapsed":120,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}},"outputId":"81b744a7-3e71-495b-946b-8e486fb4472a"},"source":["print(score)"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["0.0037410494919325977\n"]}]},{"cell_type":"code","metadata":{"id":"KnDhwceSWDZN","executionInfo":{"status":"ok","timestamp":1632256320625,"user_tz":240,"elapsed":1103,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}}},"source":["from datasets import load_metric\n","import bert_score\n","metric = load_metric(\"bertscore\")"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"leC5zjbiWWwr","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["fc3021ecf93f433d8b3ef7aa2c0c161a","c199c2933b284e6aa4cb98e0f56d52c1","d24d1a4d33fe455e979377ff7732ccb9","d20629a3ae2c436eae99c2ccd97e89d8","8a05072c5a6746d5bd88dd010f3a53c7","50b645bd88d54f0e88aed1cf2d845d8b","766564d2582145359d0d9875e46c119c","158b80c54af8464fbaebf07af0a4d0ce","3cd2e3adc5a448ffbacf87c82497df1d","8d2ef5761efc4c12b6d940c26af7296a","17b8e81a338a485487e0ecf80f2e86bf"]},"executionInfo":{"status":"ok","timestamp":1632256321535,"user_tz":240,"elapsed":177,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}},"outputId":"f9ff2332-58ba-4129-ed9b-dcf41717ffe2"},"source":["lis_of_h = []\n","lis_of_r = []\n","for i in tqdm(range(len(list_of_hypotheses))):\n","  h = list_of_hypotheses[i][0]\n","  r = ' '.join(list_of_references[i][0])\n","  lis_of_h.append(h)\n","  lis_of_r.append(r)"],"execution_count":25,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc3021ecf93f433d8b3ef7aa2c0c161a","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/40 [00:00<?, ?it/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"jY2zs6IhXWvA","colab":{"base_uri":"https://localhost:8080/","height":220,"referenced_widgets":["c2a6534214664e43b9020fb99d918fcc","cf1b340bec934f3497edff52909f1192","70f71f39a8d44a7189560de131994dfe","42e29973b0f548a5b1dbea8cc56705bc","6872508b3fe14e82aa89defc2cc8c27a","dfd1241c3c4942cd9f52f0243a070090","27d3e5c63dff435aad75f85d957487cf","e673a3c245d04a729ba4ef7538224dbb","788d6dd63eb24f41afaedfe7e3559946","edae84f822aa4fc6a7589875f81895f2","e6867fd02a44438bbf64e290811ab76d","483b52f5c60742ae99bd327272a73678","0731336725ce4695a1a59580fa46f291","e06c0afe8534487c9c5d6dc445320cc6","154ae5f748f349f88e4beeae2c3e57fc","a8cf05838eed45f89dac6221936688c3","d7ca8b4c0a5242599837e251d9b32307","117c945d401e4e4ca221970caf46f75c","0908ee1b10994d28a763026034198c61","f2e7338ead9a4dedae516f0803c02aaa","40ea2470257140d99e0fd8f9b657c588","e2809e3824d941e4ae3f05efaece9294"]},"executionInfo":{"status":"ok","timestamp":1632256332501,"user_tz":240,"elapsed":8430,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}},"outputId":"ff2349a6-4d06-4c9e-8131-c76e82f2c87e"},"source":["P, R, F1 = bert_score.score(lis_of_h, lis_of_r, lang='en', verbose=True)\n"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["calculating scores...\n","computing bert embedding.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c2a6534214664e43b9020fb99d918fcc","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["computing greedy matching.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"483b52f5c60742ae99bd327272a73678","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["done in 1.69 seconds, 23.64 sentences/sec\n"]}]},{"cell_type":"code","metadata":{"id":"Q5et8X_mYOw4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632256334156,"user_tz":240,"elapsed":65,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}},"outputId":"8d7e8c3c-e3a4-421d-c7cb-df12fc709d3d"},"source":["print(F1)\n","print(f\"System level F1 score: {F1.mean():.3f}\")\n","print(f\"System level Precision: {P.mean():.3f}\")\n","print(f\"System level Recall: {R.mean():.3f}\")"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.7847, 0.7752, 0.7993, 0.7738, 0.7733, 0.7896, 0.7762, 0.7804, 0.7673,\n","        0.7836, 0.7724, 0.7894, 0.7779, 0.7823, 0.7750, 0.7853, 0.7747, 0.8018,\n","        0.7928, 0.7835, 0.7821, 0.7749, 0.7671, 0.7691, 0.8144, 0.7900, 0.7733,\n","        0.7757, 0.7827, 0.7720, 0.7888, 0.7747, 0.7746, 0.8028, 0.7948, 0.7813,\n","        0.7684, 0.7776, 0.7813, 0.7764])\n","System level F1 score: 0.782\n","System level Precision: 0.780\n","System level Recall: 0.783\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":164},"id":"OVYMGj--J5l0","executionInfo":{"status":"error","timestamp":1632254017512,"user_tz":240,"elapsed":74,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12010089611056364005"}},"outputId":"92a2d1dd-6c89-4907-c397-7c155c4cf2c8"},"source":["print(list_of_pp[0].item())"],"execution_count":null,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-3729bd5485f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_pp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"code","metadata":{"id":"BbwA16a1YOUK"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HBlw1J5KKQ7G","executionInfo":{"status":"ok","timestamp":1617730759438,"user_tz":240,"elapsed":745,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjKY9dxkJ_1DuEZ_E-G0PfzDJQdNDSLAc0EcvuHQ=s64","userId":"14864098516282807303"}},"outputId":"34b98ef1-89cf-4da2-8ab6-f6c59408968e"},"source":["sum = 0\n","for i in range(len(list_of_pp)):\n","  sum += list_of_pp[i].item()\n","print(sum/300)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.758521210749944\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DDkgrFOBZh19"},"source":["from tqdm.notebook import tqdm\n","model =  BartForConditionalGeneration.from_pretrained(WEIGHT_PATH)\n","model.to(device)\n","generated_sen = []\n","\n","for i in tqdm(range(0,3441)):\n","  sentence = data[i][1][0]\n","  tokenize_input = tokenizer.tokenize(sentence)\n","  tensor_input = torch.tensor([tokenizer.convert_tokens_to_ids(tokenize_input)]).to(device)\n","  a = model.generate(tensor_input,\n","                do_sample=True,\n","                max_length=600,\n","                temperature=1.0,\n","                top_k=5,\n","                top_p=0.9,\n","                repetition_penalty=1.0,\n","                )\n","  text = ''\n","  for w in a:\n","    text += tokenizer.decode(w, clean_up_tokenization_spaces=True)\n","  generated_sen.append(text)\n","  #print(text)\n","'''\n","import json\n","PATH = \"/content/drive/MyDrive/Colab Notebooks/NLP/\"\n","f = open(PATH + \"generated_sentences.json\",'w')\n","json.dump(generated_sen, f)\n","\n","f.close()\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TwWzTzRTGaBl","executionInfo":{"status":"ok","timestamp":1616654226324,"user_tz":240,"elapsed":573,"user":{"displayName":"Jason Qi","photoUrl":"","userId":"14258838799704967372"}},"outputId":"08d86e1a-86cf-4175-9f95-0b3a403f7110"},"source":["print(len(generated_sen))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3441\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZHEqTSgItLEA","executionInfo":{"status":"ok","timestamp":1616653539298,"user_tz":240,"elapsed":554,"user":{"displayName":"Jason Qi","photoUrl":"","userId":"14258838799704967372"}},"outputId":"c173a3bf-f9a0-4a65-df3d-ade933da4c8f"},"source":["print(generated_sen[7])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["</s><s>Hi, good morning. Thanks for taking my question. I wanted to follow-up on OptumInsight’s operating margin guidance. So, you’re guiding to about 25% operating margin in fiscal ‘19. You’ve got OptumRx now at 20%, OptumNow at 20%. So, I’m just trying to get a sense of how much of that is coming from Optum insight versus Optum Insight? And then, my second question is just around the Optum business. I think, historically, Optum has been in the mid-single-digit operating margin range for a couple of years, but now, you are moving closer to the upper end of that range. And I was just wondering if you could give us a little bit more color on what you think is driving that relative to your long-term target of 30% to 40% operating margins? Thank you.</s>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HblscpXo_FNk","executionInfo":{"status":"ok","timestamp":1616719410869,"user_tz":240,"elapsed":693,"user":{"displayName":"Jason Qi","photoUrl":"","userId":"14258838799704967372"}},"outputId":"12e4dccf-8f48-447f-f73c-79cf26eacb66"},"source":["print(list_of_pp)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[tensor(3123.8684, device='cuda:0'), tensor(722.2648, device='cuda:0')]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ml4aZGqsg30C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617731289273,"user_tz":240,"elapsed":650,"user":{"displayName":"Eric Gu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjKY9dxkJ_1DuEZ_E-G0PfzDJQdNDSLAc0EcvuHQ=s64","userId":"14864098516282807303"}},"outputId":"da04c343-570e-42cd-c248-555a505b6abe"},"source":["print(score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_VxeWeNwTXvb"},"source":["from pprint import pprint"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ATDlTRTkvr5O"},"source":["for i in range(len(list_of_references)):\n","  print(\"Original:\")\n","  print(list_of_original[i])\n","  print(\"Ground Truth:\")\n","  print(' '.join(list_of_references[i][0]))\n","  print(\"Generated: \")\n","  print(list_of_hypotheses[i])\n","  print(\"-------------------------------\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":428,"referenced_widgets":["26ac92ef5e85432587c9b565ed8710b1","6333f574423846f2a4d12f9e5b63c999","96ff87e1a1164975b3042e1bf9f2d348","80c5541bc989413486a05a63dbefc877","e3f8726cab8347438ffb1dc97380e4c0","0212789179df4e6ca0000e3c23e44257","9d04151b756f4f0fb3bdcf89a07cad34","dca4268d4a044b909f594cab25b01f5f","7a1ebcd4ec9c46d5ae87dca458153d0a","2a7b7f8e56474e46b64f81476ae47e9d","73b46d2545d141d19e1ff9b64224c74c","b7a42baa898947bc8fe39f6bd114ed6c","58e6c289bc024bc88bcba1cc0a456585","b22ef88cf4874ee991843661220b3e74","4884fb263261439898cb134872c5dc33","77fe5031a689459490ed7c334c422a0c"]},"id":"eale0Pr6X-a8","executionInfo":{"status":"error","timestamp":1616528959015,"user_tz":240,"elapsed":4898,"user":{"displayName":"Jason Qi","photoUrl":"","userId":"14258838799704967372"}},"outputId":"44b5fb7e-1de9-42c6-d6a5-752e52239eb5"},"source":["from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n","from tqdm.notebook import tqdm\n","device = 'cuda:0'\n","model_id = 'gpt2-large'\n","gpt_model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n","tokenizer = GPT2TokenizerFast.from_pretrained(model_id)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"26ac92ef5e85432587c9b565ed8710b1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=764.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7a1ebcd4ec9c46d5ae87dca458153d0a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=3247202234.0, style=ProgressStyle(descr…"]},"metadata":{"tags":[]}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-e9f0f079024d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gpt2-large'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2LMHeadModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2TokenizerFast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                     \u001b[0mresume_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                     \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                     \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m                 )\n\u001b[1;32m   1039\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEnvironmentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m         )\n\u001b[1;32m   1144\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1386\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found in cache or force_download set to True, downloading to %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m             \u001b[0mhttp_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_to_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storing %s in cache at %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTSET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m     )\n\u001b[0;32m-> 1251\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \"\"\"\n\u001b[1;32m    408\u001b[0m         \u001b[0mSimilar\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mhttplib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtwo\u001b[0m \u001b[0madditional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BCtc9W-IX_ce","executionInfo":{"status":"ok","timestamp":1616528954107,"user_tz":240,"elapsed":32431,"user":{"displayName":"Jason Qi","photoUrl":"","userId":"14258838799704967372"}},"outputId":"4f9fd04a-b55a-4a21-fc80-87a335e78de8"},"source":["import math\n","import torch\n","!pip install pytorch_pretrained_bert\n","from pytorch_pretrained_bert import OpenAIGPTTokenizer, OpenAIGPTModel, OpenAIGPTLMHeadModel\n","# Load pre-trained model (weights)\n","model = OpenAIGPTLMHeadModel.from_pretrained('openai-gpt')\n","model.eval()\n","# Load pre-trained model tokenizer (vocabulary)\n","tokenizer = OpenAIGPTTokenizer.from_pretrained('openai-gpt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pytorch_pretrained_bert\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\r\u001b[K     |██▋                             | 10kB 18.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 25.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 30.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 23.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 14.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 12.0MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.19.5)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.8.0+cu101)\n","Collecting boto3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/3d/386cc84db1e57aa7782eed00bcbdb884e496bdb1689c7f4c09a22572846d/boto3-1.17.35-py2.py3-none-any.whl (131kB)\n","\u001b[K     |████████████████████████████████| 133kB 20.3MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.7.4.3)\n","Collecting jmespath<1.0.0,>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Collecting s3transfer<0.4.0,>=0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/14/0b4be62b65c52d6d1c442f24e02d2a9889a73d3c352002e14c70f84a679f/s3transfer-0.3.6-py2.py3-none-any.whl (73kB)\n","\u001b[K     |████████████████████████████████| 81kB 6.7MB/s \n","\u001b[?25hCollecting botocore<1.21.0,>=1.20.35\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/1d/e6ea5f2f856262415eb252b035fdb3524eeff4bb27864f7363a9bce5439f/botocore-1.20.35-py2.py3-none-any.whl (7.3MB)\n","\u001b[K     |████████████████████████████████| 7.3MB 18.5MB/s \n","\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.35->boto3->pytorch_pretrained_bert) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.35->boto3->pytorch_pretrained_bert) (1.15.0)\n","\u001b[31mERROR: botocore 1.20.35 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n","Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n","Successfully installed boto3-1.17.35 botocore-1.20.35 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.3.6\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 478750579/478750579 [00:19<00:00, 25116217.55B/s]\n","100%|██████████| 656/656 [00:00<00:00, 409870.91B/s]\n","100%|██████████| 815973/815973 [00:00<00:00, 1911495.38B/s]\n","100%|██████████| 458495/458495 [00:00<00:00, 1281637.38B/s]\n","ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":331},"id":"14qxl0tkZ5SO","executionInfo":{"status":"error","timestamp":1616528919357,"user_tz":240,"elapsed":544,"user":{"displayName":"Jason Qi","photoUrl":"","userId":"14258838799704967372"}},"outputId":"abf47425-0378-487d-8a6d-573215b956c9"},"source":["def score(sentence):\n","    tokenize_input = tokenizer.tokenize(sentence)\n","    tensor_input = torch.tensor([tokenizer.convert_tokens_to_ids(tokenize_input)])\n","    loss=model(tensor_input, lm_labels=tensor_input)\n","    return math.exp(loss)\n","\n","a = [\"i wrote a book, i wrote a book, i wrote a book, i wrote a book,i wrote a book, i wrote a book.\",\n","   \"i wrote a book.\",\n","   \"i wrote a book about the life of two young people who fall in love with each other.\"]\n","     \n","print([score(i) for i in a])"],"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-182398d547e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m    \"i wrote a book about the life of two young people who fall in love with each other.\"]\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-26-182398d547e7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m    \"i wrote a book about the life of two young people who fall in love with each other.\"]\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-26-182398d547e7>\u001b[0m in \u001b[0;36mscore\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtokenize_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtensor_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'lm_labels'"]}]},{"cell_type":"code","metadata":{"id":"9iDx9oBBbU_s"},"source":["def pp_score(model, sentence,  mask_token_id=103):\n","  tensor_input = sentence\n","  repeat_input = tensor_input.repeat(tensor_input.size(-1)-2, 1)\n","  mask = torch.ones(tensor_input.size(-1) - 1).diag(1)[:-2]\n","  masked_input = repeat_input.masked_fill(mask == 1, 103)\n","  labels = repeat_input.masked_fill( masked_input != 103, -100)\n","  loss,_ = model(masked_input, masked_lm_labels=labels)\n","  result = np.exp(loss.item())\n","  return result"],"execution_count":null,"outputs":[]}]}